import cv2
from ultralytics import YOLO

# ğŸ“¦ Classes Ã  flouter : personne = 0, chat = 15, chien = 16 dans COCO
CLASSES_TO_BLUR = [0, 15, 16]  # person, cat, dog

def flouter_video(input_path, output_path):
    """
    Floute les personnes et animaux domestiques dans une vidÃ©o.
    
    Args:
        input_path (str): Chemin vers la vidÃ©o originale.
        output_path (str): Chemin vers la vidÃ©o floutÃ©e.
    """
    # âœ… Charger le modÃ¨le YOLOv8 (modÃ¨le lÃ©ger 'n' = nano)
    model = YOLO('yolov8n.pt')

    # âœ… Ouvrir la vidÃ©o originale
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        print("[âŒ] Impossible d'ouvrir la vidÃ©o :", input_path)
        return

    # ğŸ“ RÃ©cupÃ©rer infos sur la vidÃ©o
    fps = cap.get(cv2.CAP_PROP_FPS)
    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # ğŸ¥ CrÃ©er l'objet pour enregistrer la vidÃ©o de sortie
    fourcc = cv2.VideoWriter_fourcc(*"avc1")  # ou "H264" si "avc1" ne marche pas
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    print("[ğŸš€] DÃ©but du traitement de la vidÃ©o...")

    while True:
        success, frame = cap.read()
        if not success:
            break  # fin de la vidÃ©o

        # ğŸ§  Appliquer la dÃ©tection avec YOLO
        results = model(frame, verbose=False)[0]

        for box in results.boxes:
            cls = int(box.cls.item())  # classe dÃ©tectÃ©e
            if cls in CLASSES_TO_BLUR:
                # ğŸ“¦ CoordonnÃ©es du rectangle de la dÃ©tection
                x1, y1, x2, y2 = map(int, box.xyxy[0])

                # ğŸ”’ S'assurer qu'on reste dans les dimensions de l'image
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(width, x2), min(height, y2)

                # ğŸ¯ Appliquer le flou sur la zone dÃ©tectÃ©e
                roi = frame[y1:y2, x1:x2]
                roi_blur = cv2.GaussianBlur(roi, (51, 51), 30)
                frame[y1:y2, x1:x2] = roi_blur

        # ğŸ’¾ Ajouter la frame floutÃ©e dans la vidÃ©o finale
        out.write(frame)

    # âœ… LibÃ©rer les ressources
    cap.release()
    out.release()
    print("[âœ…] VidÃ©o floutÃ©e enregistrÃ©e sous :", output_path)
